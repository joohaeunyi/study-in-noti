{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e74435",
   "metadata": {},
   "source": [
    "### Rerank  \n",
    "  \n",
    "- 주어진 순위를 재정렬하여 더 나은 순위를 제공하는 작업  \n",
    "- 정보 검색, 추천 시스템 등 순위가 영향을 미치는 영역에서 사용  \n",
    "- 기본 아이디어는 초기 순위를 생성한 후에 추가적인 특성이나 기준을 고려하여 더 나은 순위를 만드는 것  \n",
    "실시간 ?? 예시가 기억이 안난당\n",
    "\n",
    "#### Rerank 알고리즘의 종류  \n",
    "1. Learning to Rank(LTR)  \n",
    "- 기계 학습 기술을 사용하여 초기 순위를 향상시키는 방법  \n",
    "- RankNet, LambdaMART, RankBoost 등이 존재  \n",
    "- 특징을 추출하고 학습하여 더 나은 순위를 생성  \n",
    "  \n",
    "2. Relevance Feedback  \n",
    "- 사용자 피드백을 기반으로 초기 순위를 개선\n",
    "- 사용자가 선택한 항목에 대한 피드백을 수집하여 해당 정보를 활용하여 순위 조정  \n",
    "  \n",
    "3. Query Expansion  \n",
    "- 초기 검색 쿼리를 확장하여 다양한 관련 용어를 포함하여 초기 순위를 개선\n",
    "- 검색 쿼리를 향상시켜 더 많은 관련 문서를 찾는데 도움을 줌  \n",
    "  \n",
    "4. Diversification  \n",
    "- 다양성 증가시켜 사용자가 다양한 관점에서 정보를 확인할 수 있도록 하는 방법  \n",
    "  \n",
    "5. Temporal Reranking  \n",
    "- 시간적 특성을 고려하여 검색 겨로가를 재정렬하는 방법  \n",
    "- 실시간 이벤트나 트렌드에 관련된 검색에 유용  \n",
    "  \n",
    "6. User Context-based Reranking  \n",
    "- 사용자 정보 기반 초기 순위 개선  \n",
    "- 사용자 위치, 장치, 이전 검색 기록을 고려하여 더 관련성 높은 결과를 제공  \n",
    "  \n",
    "7. Combination Approaches \n",
    "- 여러 reranking 전략을 결합하여 더 나은 결과를 달성하는 방법  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde1e94",
   "metadata": {},
   "source": [
    "### Rerank 기본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2da0073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked Results:\n",
      "Document ID: 5, Rerank Score: 495.0\n",
      "Document ID: 3, Rerank Score: 420.0\n",
      "Document ID: 1, Rerank Score: 400\n",
      "Document ID: 2, Rerank Score: 240\n",
      "Document ID: 4, Rerank Score: 225.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 초기 순위를 가정한 데이터 (예: 검색 결과)\n",
    "initial_ranking = [\n",
    "    {'document_id': 1, 'score': 4},\n",
    "    {'document_id': 2, 'score': 3},\n",
    "    {'document_id': 3, 'score': 3.5},\n",
    "    {'document_id': 4, 'score': 2.5},\n",
    "    {'document_id': 5, 'score': 4.5}\n",
    "]\n",
    "\n",
    "# 추가 특성 데이터 (예: 문서의 길이)\n",
    "additional_features = {\n",
    "    1: {'length': 100},\n",
    "    2: {'length': 80},\n",
    "    3: {'length': 120},\n",
    "    4: {'length': 90},\n",
    "    5: {'length': 110}\n",
    "}\n",
    "\n",
    "# reranking을 위한 함수\n",
    "def rerank(initial_ranking, additional_features):\n",
    "    '''\n",
    "    문서의 길이와 스코어를 조합하여 리랭킹\n",
    "    문서의 길이와 스코어를 조합한 결과로 소팅할 것(높은 순)    \n",
    "    '''    \n",
    "    reranked_list = []\n",
    "\n",
    "    lst = []\n",
    "    for i in range(len(initial_ranking)):\n",
    "        lst.append(initial_ranking[i]['score']*additional_features[i+1]['length']) # 스코어 * 길이 값 lst에 저장\n",
    "\n",
    "    df = pd.DataFrame(lst, index=[i+1 for i in range(5)])\n",
    "    df = df.sort_values(0, ascending=False)\n",
    "    i_lst = list(df.index)\n",
    "    new_score_lst = []\n",
    "    for i in range(len(initial_ranking)): # new_score_dct 생성\n",
    "        new_score_lst.append({'document_id': i+1, 'score': lst[i]})\n",
    "    for i in range(len(new_score_lst)):\n",
    "        reranked_list.append(new_score_lst[i_lst[i]-1])\n",
    "    return reranked_list\n",
    "\n",
    "# reranking 수행\n",
    "reranked_results = rerank(initial_ranking, additional_features)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Reranked Results:\")\n",
    "for item in reranked_results:\n",
    "    print(f\"Document ID: {item['document_id']}, Rerank Score: {item['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8deac3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked Results:\n",
      "Document ID: 5, Rerank Score: 495.0\n",
      "Document ID: 3, Rerank Score: 420.0\n",
      "Document ID: 1, Rerank Score: 400\n",
      "Document ID: 2, Rerank Score: 240\n",
      "Document ID: 4, Rerank Score: 225.0\n"
     ]
    }
   ],
   "source": [
    "# claude 답\n",
    "import numpy as np\n",
    "\n",
    "# 초기 순위를 가정한 데이터 (예: 검색 결과)\n",
    "initial_ranking = [\n",
    "    {'document_id': 1, 'score': 4},\n",
    "    {'document_id': 2, 'score': 3},\n",
    "    {'document_id': 3, 'score': 3.5},\n",
    "    {'document_id': 4, 'score': 2.5},\n",
    "    {'document_id': 5, 'score': 4.5}\n",
    "]\n",
    "\n",
    "# 추가 특성 데이터 (예: 문서의 길이)\n",
    "additional_features = {\n",
    "    1: {'length': 100},\n",
    "    2: {'length': 80},\n",
    "    3: {'length': 120},\n",
    "    4: {'length': 90},\n",
    "    5: {'length': 110}\n",
    "}\n",
    "\n",
    "def rerank(initial_ranking, additional_features):\n",
    "    \n",
    "    # 스코어와 길이를 조합하여 새로운 점수 계산\n",
    "    reranked_scores = [item['score'] * additional_features[item['document_id']]['length'] for item in initial_ranking]\n",
    "\n",
    "    # 새로운 점수를 기준으로 initial_ranking을 정렬.\n",
    "    # zip을 sorted 하면 첫번째 요소를 기준으로 정렬\n",
    "    reranked_results = [item for _, item in sorted(zip(reranked_scores, initial_ranking), reverse=True)]\n",
    "    reranked_scores.sort(reverse=True)\n",
    "\n",
    "    # 정렬된 리스트에 새로운 점수 추가\n",
    "    for i, item in enumerate(reranked_results):\n",
    "        item['score'] = reranked_scores[i]\n",
    "    \n",
    "    return reranked_results\n",
    "\n",
    "# reranking 수행\n",
    "reranked_results = rerank(initial_ranking, additional_features)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Reranked Results:\")\n",
    "for item in reranked_results:\n",
    "    print(f\"Document ID: {item['document_id']}, Rerank Score: {item['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "946e8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked Results:\n",
      "Document ID: 5, Rerank Score: 495.0\n",
      "Document ID: 3, Rerank Score: 420.0\n",
      "Document ID: 1, Rerank Score: 400\n",
      "Document ID: 2, Rerank Score: 240\n",
      "Document ID: 4, Rerank Score: 225.0\n"
     ]
    }
   ],
   "source": [
    "# gpt 답\n",
    "\n",
    "initial_ranking = [\n",
    "    {'document_id': 1, 'score': 4},\n",
    "    {'document_id': 2, 'score': 3},\n",
    "    {'document_id': 3, 'score': 3.5},\n",
    "    {'document_id': 4, 'score': 2.5},\n",
    "    {'document_id': 5, 'score': 4.5}\n",
    "]\n",
    "\n",
    "additional_features = {\n",
    "    1: {'length': 100},\n",
    "    2: {'length': 80},\n",
    "    3: {'length': 120},\n",
    "    4: {'length': 90},\n",
    "    5: {'length': 110}\n",
    "}\n",
    "\n",
    "# reranking을 위한 함수\n",
    "def rerank(initial_ranking, additional_features):\n",
    "    # 문서의 길이와 스코어를 조합하여 리랭킹\n",
    "    reranked_list = []\n",
    "\n",
    "    for doc in initial_ranking:\n",
    "        doc_id = doc['document_id']\n",
    "        score = doc['score']\n",
    "        length = additional_features[doc_id]['length']\n",
    "        combined_score = score * length  # 스코어와 길이를 곱하여 새 스코어 계산\n",
    "        reranked_list.append({'document_id': doc_id, 'score': combined_score})\n",
    "\n",
    "    # 새로운 스코어(rerank_score)로 내림차순 정렬\n",
    "    reranked_list.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    return reranked_list\n",
    "\n",
    "reranked_results = rerank(initial_ranking, additional_features)\n",
    "\n",
    "print(\"Reranked Results:\")\n",
    "for item in reranked_results:\n",
    "    print(f\"Document ID: {item['document_id']}, Rerank Score: {item['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05564c2",
   "metadata": {},
   "source": [
    "### RankNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c7f94",
   "metadata": {},
   "source": [
    "- 주어진 문서들을 비교하여 문서들의 특성을 습득  \n",
    "- 새로 주어진 문서는 어떤 문서와 유사한지 예측하는 알고리즘  \n",
    "\n",
    "#### 작동 원리  \n",
    "1. Input Representation  \n",
    "- 각 문서는 특징 벡터로 표현  \n",
    "- 특징 벡터: 문서의 속성으로 TF-IDF 혹은 문서 길이, 종류 등  \n",
    "  \n",
    "2. Pairwise Comparison  \n",
    "- 주어진 문서들을 비교하여 상대적인 순서를 학습  \n",
    "  \n",
    "3. Training  \n",
    "- 신경망을 통해 학습\n",
    "- 예측된 순서와 실제 순서 간의 차이를 최소화하는 방법으로 가중치를 조정  \n",
    "  \n",
    "4. Ranking\n",
    "- 학습된 RankNet 모델을 사용하여 새로운 문서들의 순위를 예측  \n",
    "- 각 문서에 대한 점수를 출력하고 이를 기반으로 최종 순위를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4efe803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.6969 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6914 - accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6869 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6835 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Predicted ranking: [[0.49739432]]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "# 간단한 데이터셋 생성\n",
    "# 각 문서는 3개의 특징을 가짐\n",
    "# 두 문서 쌍의 순서가 주어짐 (1: 첫 번째 문서가 더 관련성이 높음, 0: 두 번째 문서가 더 관련성이 높음)\n",
    "X_train = np.array([[0.1, 0.2, 0.3], [0.3, 0.2, 0.5]])\n",
    "y_train = np.array([1, 0])\n",
    "\n",
    "# RankNet 모델 정의\n",
    "model = tf.keras.Sequential()\n",
    "'''\n",
    "첫번째 dense layer hidden_size: 64, activation: relu\n",
    "두번째 dense layer hidden_size: 32, activation: relu\n",
    "세번째 dense layer hidden_size: 1, activation: sigmoid\n",
    "'''\n",
    "# )\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "'''\n",
    " 2개이므로 2개에 맞는 로스함수 설정\n",
    " 옵티마이저: 아담\n",
    " 메트릭: 정확도\n",
    "'''\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "# 모델 학습\n",
    "'''\n",
    " 에폭 10\n",
    "'''\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# 학습된 모델을 사용하여 순위 예측\n",
    "X_test = np.array([[0.2, 0.3, 0.4]])\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predicted ranking:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3dc1b661",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 학습된 모델을 사용하여 순위 예측\u001b[39;00m\n\u001b[0;32m     40\u001b[0m X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# RankNet 모델 정의\n",
    "class RankNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size2):\n",
    "        super(RankNet, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# 데이터셋 생성\n",
    "# 각 문서는 3개의 특징을 가짐\n",
    "# 두 문서 쌍의 순서가 주어짐 (1: 첫 번째 문서가 더 관련성이 높음, 0: 두 번째 문서가 더 관련성이 높음)\n",
    "X_train = torch.tensor([[0.1, 0.2, 0.3], [0.3, 0.2, 0.5]], dtype=torch.float32)\n",
    "y_train = torch.tensor([1, 0], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# RankNet 모델 초기화\n",
    "input_size = torch.zeros(X_train.shape)\n",
    "hidden_size = torch.zeros(8,8)\n",
    "hidden_size2 = ''\n",
    "model = RankNet(input_size, hidden_size, hidden_size2)\n",
    "\n",
    "# Loss 및 Optimizer 정의\n",
    "criterion = torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "optimizer = ''\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    '''\n",
    "    '''\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 학습된 모델을 사용하여 순위 예측\n",
    "X_test = torch.tensor([[0.2, 0.3, 0.4]], dtype=torch.float32)\n",
    "predictions = model(X_test)\n",
    "print(\"Predicted ranking:\", predictions.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a7128fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
