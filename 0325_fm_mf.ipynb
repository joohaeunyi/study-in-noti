{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3faa4f42",
   "metadata": {},
   "source": [
    "### FM (Factorization Machines)과 MF (Matrix Factorization) 설명 \n",
    "\n",
    "#### FM (Factorization Machines)  \n",
    "  \n",
    "FM은 선형 모델의 확장으로, 고차원의 데이터에서 상호 작용을 고려하여 모델링할 수 있습니다.  \n",
    "주로 특징 간의 상호 작용을 고려하여 예측을 수행하는 데 사용됩니다.  \n",
    "FM은 일반적으로 희소한 데이터에 효과적이며, 특징 간의 관계를 학습하기 위해 사용됩니다.  \n",
    "FM은 높은 차원의 희소 데이터에 적합하며, 예를 들어 사용자와 상품 간의 상호 작용을 고려할 때 유용합니다.  \n",
    "\n",
    "#### MF (Matrix Factorization)  \n",
    "  \n",
    "MF는 행렬 분해를 기반으로 하여 사용자와 상품 간의 관계를 학습하는 데 사용됩니다.  \n",
    "주로 사용자-상품 평점 행렬과 같은 행렬 데이터를 분해하여 사용합니다.  \n",
    "MF는 사용자와 상품을 잠재적인 요인 공간(latent factor space)에 매핑하여 사용자와 상품 간의 상호 작용을 모델링합니다.  \n",
    "MF는 주로 사용자-상품 평가 예측에 사용되며, 추천 시스템에서 널리 사용됩니다.  \n",
    "\n",
    "\n",
    "#### 공통점  \n",
    "각각의 변수를 f차원의 latent Factor로 매핑하여 변수간의 상관관계를 Latent Factor의 내적으로 모델링 \n",
    "  \n",
    "#### 차이점\n",
    "mf는 user, item, rating 만을 사용. 반면 fm은 다양한 feature를 concatnate하여 사용  \n",
    "mf는 user * item의 내적으로 rating을 계산, 여기서 식은 user*item=rating  \n",
    "반면 fm은 하나의 특성 벡터로 치환, user|item|기타feature1=rating 즉 다항회귀와 유사\n",
    "fm은 sparse data에서도 파라메터 추정 가능  \n",
    "fm은 변수간의 상호작용을 고려하여 예측 가능  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56851e01",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# DictVectorizer를 사용하여 데이터를 희소 행렬로 변환\u001b[39;00m\n\u001b[1;32m     11\u001b[0m v \u001b[38;5;241m=\u001b[39m DictVectorizer()\n\u001b[0;32m---> 12\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 타겟 값 추출\u001b[39;00m\n\u001b[1;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m df]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_extraction/_dict_vectorizer.py:313\u001b[0m, in \u001b[0;36mDictVectorizer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a list of feature name -> indices mappings and transform X.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Like fit(X) followed by transform(X), but does not require\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m        Feature vectors; always 2-d.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_extraction/_dict_vectorizer.py:223\u001b[0m, in \u001b[0;36mDictVectorizer._transform\u001b[0;34m(self, X, fitting)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# collect all the possible feature names and build sparse matrix at\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# same time\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    225\u001b[0m             feature_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseparator, v)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "#FM (Factorization Machines)\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from fastFM import als\n",
    "\n",
    "# 훈련 데이터 생성 (예시)\n",
    "# 데이터 로드 및 설정\n",
    "df = pd.read_csv('dataset/ratings.csv')\n",
    "\n",
    "\n",
    "data = ''\n",
    "'''\n",
    "df를 [{column1:row1_value1,column2:row1_value2},\n",
    "    {column1:row2_value1,column2:row2_value2},\n",
    "    ...\n",
    "    의 형태로 변환\n",
    "]\n",
    "'''\n",
    "\n",
    "# DictVectorizer를 사용하여 데이터를 희소 행렬로 변환\n",
    "v = DictVectorizer() \n",
    "X = v.fit_transform(data)\n",
    "\n",
    "# 타겟 값 추출\n",
    "y = [d['rating'] for d in df]\n",
    "print(y)\n",
    "'''\n",
    "# 훈련 및 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# FM 모델 훈련\n",
    "fm = als.FMClassification(n_iter=1000, init_stdev=0.1, rank=10, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = fm.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"FM 정확도:\", accuracy)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e13b2777",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() takes exactly 2 positional arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# MF 모델 훈련\u001b[39;00m\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m SVD()\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 예측 수행\u001b[39;00m\n\u001b[1;32m     25\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtest()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx:152\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() takes exactly 2 positional arguments (1 given)"
     ]
    }
   ],
   "source": [
    "# Matrix Factorization (MF) 구현\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# 데이터 로드 및 설정\n",
    "df = pd.read_csv('dataset/ratings.csv')\n",
    "\n",
    "#userId,movieId,rating\n",
    "reader = Reader(line_format='user item rating', sep=',', rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# 훈련 및 테스트 데이터로 분할\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# MF 모델 훈련\n",
    "model = SVD()\n",
    "model.fit()\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.test()\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_mf = accuracy.rmse(predictions)\n",
    "print(\"MF 정확도:\", accuracy_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31249ca1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 그리드 서치를 사용하여 최적의 매개변수 찾기\u001b[39;00m\n\u001b[1;32m      7\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(SVD, param_grid, measures\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 최적의 매개변수 출력\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최적의 매개변수:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gs\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# SVD 모델의 매개변수 그리드 설정\n",
    "param_grid = {'n_factors': [1, 5], 'n_epochs': [1, 3], 'lr_all': [0.005, 0.01, 0.02], 'reg_all': [0.02, 0.05, 0.1]}\n",
    "\n",
    "# 그리드 서치를 사용하여 최적의 매개변수 찾기\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=20)\n",
    "gs.fit()\n",
    "\n",
    "# 최적의 매개변수 출력\n",
    "print(\"최적의 매개변수:\", gs.best_params['rmse'])\n",
    "\n",
    "# 최적의 매개변수로 모델 초기화 및 훈련\n",
    "best_model = gs.best_estimator['rmse']\n",
    "best_model.fit()\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "predictions = best_model.test()\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_mf = accuracy.rmse(predictions)\n",
    "print(\"MF 정확도:\", accuracy_mf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fde9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
