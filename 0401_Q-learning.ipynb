{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e96c2d9",
   "metadata": {},
   "source": [
    "# Q-learning 알고리즘의 개념 구현\n",
    "\n",
    "Q-learning 알고리즘을 사용하여 에이전트가 격자 세계에서 목표 지점까지 최단 경로를 찾도록 학습시키는 프로그램을 작성하세요.\n",
    "\n",
    "5x5 크기의 격자 세계를 생성하고, 에이전트의 시작 위치와 목표 위치를 임의로 설정합니다.\n",
    "에이전트는 상, 하, 좌, 우로 이동할 수 있으며, 매 이동마다 보상을 받습니다. 목표 지점에 도달하면 양의 보상을, 그 외의 경우에는 음의 보상을 받습니다.\n",
    "Q-table을 초기화하고, 에이전트를 학습시킵니다. 에이전트는 엡실론-그리디 정책을 사용하여 행동을 선택합니다.\n",
    "에이전트가 목표 지점에 도달하거나, 최대 스텝 수에 도달하면 에피소드가 종료됩니다.\n",
    "학습이 완료된 후, 학습된 Q-table을 사용하여 최적 경로를 출력합니다.\n",
    "스터디 참여자들은 위 문제를 바탕으로 다음 사항을 고려하여 코드를 작성해야 합니다:\n",
    "\n",
    "1. 5x5 격자 세계 생성 및 시각화 \n",
    "   - agent의 시작 위치와 목표 위치를 임의로 설정\n",
    "   - 에이전트는 상, 하, 좌, 우로 이동할 수 있으며, 매 이동마다 보상을 받는다. 목표 지점에 도달하면 양의 보상을, 그 외의 경우에는 음의 보상을 받는다.\n",
    "2. Q-table 초기화 및 업데이트\n",
    "3. 엡실론-그리디 정책을 사용한 행동 선택\n",
    "4. 보상 함수 정의\n",
    "5. Q-learning 알고리즘 구현\n",
    "6. 학습 결과 출력 및 최적 경로 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e5ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 1. 격자 세계 생성 및 시각화\n",
    "grid_size = 5\n",
    "start_pos = (0, 0)\n",
    "goal_pos = (4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b897a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Q-table 초기화 및 업데이트\n",
    "q_table = np.zeros((grid_size, grid_size, 4))\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3e2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 엡실론-그리디 정책을 사용한 행동 선택\n",
    "epsilon = 0.1\n",
    "\n",
    "def choose_action(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.randint(0, 3)\n",
    "    else:\n",
    "        return np.argmax(q_table[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c92b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 보상 함수 정의\n",
    "def get_reward(state):\n",
    "    return 1 if state == goal_pos else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1467c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Q-learning 알고리즘 구현\n",
    "num_episodes = 1000\n",
    "max_steps = 100\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = start_pos\n",
    "    for step in range(max_steps):\n",
    "        action = choose_action(state)\n",
    "        next_state = (state[0] + (action == 1) - (action == 0), state[1] + (action == 3) - (action == 2))\n",
    "        \n",
    "        if next_state[0] < 0 or next_state[0] >= grid_size or next_state[1] < 0 or next_state[1] >= grid_size:\n",
    "            reward = -10\n",
    "            next_state = state\n",
    "        else:\n",
    "            reward = get_reward(next_state)\n",
    "        \n",
    "        q_table[state][action] = q_table[state][action] + learning_rate * (reward + discount_factor * np.max(q_table[next_state]) - q_table[state][action])\n",
    "        state = next_state\n",
    "        \n",
    "        if state == goal_pos:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60d339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 경로:\n",
      "[(0, 0), (0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (3, 3), (4, 3), (4, 4)]\n"
     ]
    }
   ],
   "source": [
    "# 6. 학습 결과 출력 및 최적 경로 시각화\n",
    "print(\"최적 경로:\")\n",
    "state = start_pos\n",
    "path = [state]\n",
    "while state != goal_pos:\n",
    "    action = np.argmax(q_table[state])\n",
    "    state = (state[0] + (action == 1) - (action == 0), state[1] + (action == 3) - (action == 2))\n",
    "    path.append(state)\n",
    "print(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
